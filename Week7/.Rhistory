cat(k, " ")
for( j in 1:50){
S[j,k] <- sum( (Y1- (b0[j] + b1[k]*X1) )^2 )
}
}
cut (S)
cut (S, 5)
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
contour(b0, b1, S, add=TRUE,
col="grey80", nlevels=30,
lwd=3)
min(S)
min(S)/1e10
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.3,1:4)*1e10,
lwd=3)
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25.3,.5, 1:4)*1e10,
lwd=3)
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3)
source('~/Home/Teaching/APPM2720/Week7/introLS.R', echo=TRUE)
source('~/Home/Teaching/APPM2720/Week7/introLS.R', echo=TRUE)
S<- array( NA,c(50, 50))
b0<- seq( from = 20000, to = 40000, length.out = 50)
b1<- seq( from = -.4,   to = 0,     length.out = 50)
for( k in 1:50){
for( j in 1:50){
S[j,k] <- sum( (Y1- (b0[j] + b1[k]*X1) )^2 )
}
}
# take a look at the surface
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3)
# the solution "by hand" using the LS formula -- see ISLR
b1Hat =  sum( (Y1- mean(Y1)) * (X1-mean(X1)) ) / sum( (X1- mean(X1))^2)
b0Hat <-  mean(Y1) - b1Hat* mean(X1)
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3,labex=0)
# the solution "by hand" using the LS formula -- see ISLR
b1Hat =  sum( (Y1- mean(Y1)) * (X1-mean(X1)) ) / sum( (X1- mean(X1))^2)
b0Hat <-  mean(Y1) - b1Hat* mean(X1)
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labex=NA
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labex=NA)
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labex=NA)
help( "contour")
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labcex=NA)
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labcex=NA)
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, labcex=0)
source('~/Home/Teaching/APPM2720/Week7/introLS.R', echo=TRUE)
library( LatticeKrig)
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0)
x<-  cbind( c( 0,1), c(0,1))
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0)
LKinfo
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0, NC.buffer=0)
LKinfo
print.LKinfo
handyPrint<- function( LKinfo){
cat("Total number of basis functions ", LKinfo$latticeInfo$m,
fill = TRUE)
temp <- cbind(1:L, LKinfo$latticeInfo$mLevel)
dimnames(temp) <- list(rep("", L), c("Level", "Basis size"))
if (!is.null(LKinfo$latticeInfo$mx)) {
temp <- cbind(temp, LKinfo$latticeInfo$mx)
}
print(temp)
}
handyPrint( LKinfo )
handyPrint<- function( LKinfo){
cat("Total number of basis functions ", LKinfo$latticeInfo$m,
fill = TRUE)
L<- LKinfo$nlevel
temp <- cbind(1:L, LKinfo$latticeInfo$mLevel)
dimnames(temp) <- list(rep("", L), c("Level", "Basis size"))
if (!is.null(LKinfo$latticeInfo$mx)) {
temp <- cbind(temp, LKinfo$latticeInfo$mx)
}
print(temp)
}
handyPrint( LKinfo )
print( LKinfo)
handyPrint<- function( LKinfo){
cat("Total number of basis functions ", LKinfo$latticeInfo$m,
fill = TRUE)
L<- LKinfo$nlevel
temp <- cbind(1:L, LKinfo$latticeInfo$mLevel)
dimnames(temp) <- list(rep("", L), c("Level", "Basis size", "mx[1]","mx[2]"))
if (!is.null(LKinfo$latticeInfo$mx)) {
temp <- cbind(temp, LKinfo$latticeInfo$mx)
}
print(temp)
}
handyPrint( LKinfo )
handyPrint<- function( LKinfo){
cat("Total number of basis functions ", LKinfo$latticeInfo$m,
fill = TRUE)
L<- LKinfo$nlevel
temp <- cbind(1:L, LKinfo$latticeInfo$mLevel)
temp <- cbind(temp, LKinfo$latticeInfo$mx)
dimnames(temp) <- list(rep("", L), c("Level", "Basis size", "mx[1]","mx[2]"))
temp
}
handyPrint( LKinfo )
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0, NC.buffer=0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0, NC.buffer=0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=1, a.wght=5.0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=10, nlevel=1, a.wght=5.0, )
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=2, alpha=c(2,1),a.wght=5.0, NC.buffer=0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=2, alpha=c(2,1),a.wght=5.0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=4, alpha=4:1,a.wght=5.0, NC.buffer=0)
handyPrint( LKinfo)
LKinfo<- LKrigSetup( x, NC=4, nlevel=4, alpha=4:1,a.wght=5.0)
handyPrint( LKinfo)
args( rnorm)
N<- 100
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
lm( Y~X)
testFit<- function(N){
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit<-lm( Y~X)
return(fit)
}
testFit( 1e6)
testFit(4)
testFit<- function(N){
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit<-lm( Y~X)
return(fit$coefficients)
}
testFit(4)
hold<- array( NA, c(50,2))
for ( k in 1:50){
hold[k,]<- testfit( 100)
}
# little Monte Carlo run of 50 trials
hold<- array( NA, c(50,2))
for ( k in 1:50){
hold[k,]<- testFit( 100)
}
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit <- lm( Y~X)
summary( fit)
look<- summary( fit)
look
names( look)
look$sigma
N<- 100
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit <- lm( Y~X)
summary( fit)
# estimate of standard deviation of the errors
sd(fit$residuals )
# exact answer is ...
summary( fit)$sigma
N<- 100
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit <- lm( Y~X)
summary( fit)
# estimate of standard deviation of the errors
sd(fit$residuals )
# exact answer  (adjust by n-2) is ...
sd(fit$residuals ) *  sqrt( (N-1)/N-2))
summary( fit)$sigma
# exact answer  (adjust by n-2) is ...
sd(fit$residuals ) *  sqrt( (N-1)/(N-2) )
summary( fit)$sigma
hold<- array( NA, c(50,2))
for ( k in 1:100){
hold[k,]<- testFit( 100)
}
testFit<- function(N){
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit<-lm( Y~X)
return(fit$coefficients)
}
# little Monte Carlo run of 50 trials
hold<- array( NA, c(50,2))
for ( k in 1:100){
hold[k,]<- testFit( 100)
}
testFit(100)
dim( hold)
hold[10,] <- testFit(100)
hold
hold<- array( NA, c(250,2))
for ( k in 1:250){
hold[k,]<- testFit( 100)
}
Y<- rnorm( 1000, mean=2, sd=.5)
xgrid<- seq(-4, 4,length.out=500)
ycurve<- dnorm( mean=2, sd=.5)
hist(Y, prob=TRUE, col="green4")
lines( xgrid, ycurve)
Y<- rnorm( 1000, mean=2, sd=.5)
xgrid<- seq(-4, 4,length.out=500)
ycurve<- dnorm( xgrid,mean=2, sd=.5)
hist(Y, prob=TRUE, col="green4")
lines( xgrid, ycurve)
Y<- rnorm( 1e4, mean=2, sd=.5)
xgrid<- seq(-4, 4,length.out=500)
ycurve<- dnorm( xgrid,mean=2, sd=.5)
hist(Y, prob=TRUE, col="green4")
lines( xgrid, ycurve)
Y<- rnorm( 1e4, mean=2, sd=.5)
xgrid<- seq(-4, 4,length.out=500)
ycurve<- dnorm( xgrid,mean=2, sd=.5)
hist(Y, prob=TRUE, col="green4")
lines( xgrid, ycurve, col="red", lwd=2)
testFit<- function(X){
N<- length( X)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit<-lm( Y~X)
return(fit$coefficients)
}
set.seed(122)
N<- 100
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5 )
Y<- 2 + 3*X + errors
fit <- lm( Y~X)
summary( fit)
names( summary(fit))
look<- summary(fit)
look$coefficients
hold<- array( NA, c(250,2))
for ( k in 1:250){
hold[k,]<- testFit(X)
}
sd( hold[,2])
Y<- 2 + 3*X + errors
fit <- lm( Y~X)
look<-summary( fit)
look$coefficients
plot( hold)
library(rgl)
library( help="rgl-package")
library( help="rgl")
library( help=rgl)
data( AudiA4)
Y<- AudiA4$price
X<- AudiA4$mileage
# finding the mean price the hard way!
S<- rep( NA, 50)
a<- seq( from= 2000, to = 40000, length.out=50)
for( k in 1:50){
S[k] <- sum( abs(Y-a[k]) )
}
# analysis
plot( a, S, type="l")
ind<- which.min(S)
abline( v= a[ind], lwd=2, col="magenta")
abline( v= mean(Y), lwd=2)
# Q1 modify the program to find the median
# (recall absolute value function in R is abs)
plot( X,Y)
# a linear relationship might  more sense for mileage in the range [20K, 75K]
ind<-  (X>= 20000) & (X< 75000)    # & is logical 'and'
X1<- X[ind]
Y1<- Y[ind]
points( X1,Y1, col="red")
# brute force
# this is also incldued as a more substantially program and
# and an example of the image format
S<- array( NA,c(50, 50))
b0<- seq( from = 20000, to = 40000, length.out = 50)
b1<- seq( from = -.4,   to = 0,     length.out = 50)
for( k in 1:50){
for( j in 1:50){
S[j,k] <- sum( (Y1- (b0[j] + b1[k]*X1) )^2 )
}
}
# take a look at the surface
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
library(fields)
ylim <- range(y)
ylen <- ylim[2] - ylim[1] + 1
library( dataWorkshop)
# Intro to least squares
# as an example work with the AudiA4 data
#
data( AudiA4)
Y<- AudiA4$price
X<- AudiA4$mileage
# finding the mean price the hard way!
S<- rep( NA, 50)
a<- seq( from= 2000, to = 40000, length.out=50)
for( k in 1:50){
S[k] <- sum( abs(Y-a[k]) )
}
# analysis
plot( a, S, type="l")
ind<- which.min(S)
abline( v= a[ind], lwd=2, col="magenta")
abline( v= mean(Y), lwd=2)
# Q1 modify the program to find the median
# (recall absolute value function in R is abs)
plot( X,Y)
# a linear relationship might  more sense for mileage in the range [20K, 75K]
ind<-  (X>= 20000) & (X< 75000)    # & is logical 'and'
X1<- X[ind]
Y1<- Y[ind]
points( X1,Y1, col="red")
# brute force
# this is also incldued as a more substantially program and
# and an example of the image format
S<- array( NA,c(50, 50))
b0<- seq( from = 20000, to = 40000, length.out = 50)
b1<- seq( from = -.4,   to = 0,     length.out = 50)
for( k in 1:50){
for( j in 1:50){
S[j,k] <- sum( (Y1- (b0[j] + b1[k]*X1) )^2 )
}
}
# take a look at the surface
image.plot(b0, b1, S, ylab="slope", xlab="intercept")
# add another contour close to the minimum
contour(b0, b1, S, add=TRUE,
col="grey80", levels= c(.25,.3,.5, 1:4)*1e10,
lwd=3, drawlabels= FALSE)
# the solution "by hand" using the LS formula -- see ISLR
b1Hat =  sum( (Y1- mean(Y1)) * (X1-mean(X1)) ) / sum( (X1- mean(X1))^2)
b0Hat <-  mean(Y1) - b1Hat* mean(X1)
fit<- lm(Y1 ~ X1 )
# or  fit$lsfit( X1,Y1)
coef<- fit$coefficients
points( coef[1], coef[2], col="magenta", pch=16)
quartz()
p.out<- drape.plot(b0, b1, S, border=NA, col=two.colors())
pushpin(coef[1], coef[2], min(S), p.out=p.out)
library( rgl)
Slim <- range(S)
Slen <- Slim[2] - Slim[1] + 1
colorlut <- terrain.colors(Slen) # height color lookup table
Slen
Slim
rgl.open()
rgl.surface(b0,b1,S)
drape.plot
col <- tim.colors(256)
drape.info <- drape.color(S, col = col, zlim = range(S), breaks = NA)
names( drape.info)
rgl.surface(b0,b1,S, col=drape.info$color.index  )
dim( drape.info$color.index)
( drape.info$color.index)[,1]
rgl.open()
rgl.surface(b0,b1,S, col=drape.info$color.index  )
help( rgl.surface)
rgl.open()
rgl.surface(b0,b1,S, col=drape.info$color.index  )
setwd("~/Home/Teaching/APPM2720/Week7")
set.seed(145)
runif(10)
mean( X)
set.seed(123)
N<-100
X<- rnorm(N)
mean( X)
sd(X)
plot( X,Y)
errors<- rnorm( N, mean=0, sd=.5)
Y <- 2 + 3*X +errors
plot( X,Y)
quartz()
plot( X,Y)
fit<- lm(Y ~ X)
fit
set.seed(123)
N<-4
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5)
Y <- 2 + 3*X +errors
lm(Y ~ X)
plot(X,Y)
N<-4
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5)
Y <- 2 + 3*X +errors
lm(Y ~ X)
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5)
Y <- 2 + 3*X +errors
N<- 2e6
X<- rnorm(N)
errors<- rnorm( N, mean=0, sd=.5)
Y <- 2 + 3*X +errors
system.time(  lm(Y~M))
system.time(  lm(Y~X))
lm(Y~X)
testFit <- function(X){
N<- length(X)
errors<- rnorm( N, mean=0, sd=.5)
Y<- 2 + 3*X +errors
fit<- lm(Y~X)
return( fit$coefficients)
}
set.seed(123)
N<-100
X<- rnorm(N)
testFit(X)
testFit(X)
hold<- array( NA, c(250,2))
for( k in 1:250){
hold[k,]<- testFit(X)
}
hist( hold[,2])
library( fields)
stats( hold)
errors<- rnorm( N, mean=0, sd=.5)
Y<- 2 + 3*X +errors
fit<- lm(Y~X)
fit
summary( fit)
stats(hold)
library( dataWorkshop)
data(AudiA4)
Y<- AudiA4$price
X<- AudiA4$mileage
plot( X,Y)
dev.off()
dev.off()
quartz()
Y<- AudiA4$price
X<- AudiA4$mileage
plot( X,Y)
ind<- (X >= 20000) &(X<=75000)
X1<- X[ind]
Y1< Y[ind]
points( X1,Y1, col="red2")
ind<- (X >= 20000) &(X<=75000)
X1 <- X[ind]
Y1 <- Y[ind]
points( X1,Y1, col="red2")
errors<- rnorm( N, mean=0, sd=.5)
Y<- 2 + 3*X +errors
fit<- lm(Y~X)
fitGood<- lm(Y1 ~X1)
summary(fitGood)
abline(a= fitGood$coefficients[1], b= fitGood$coefficients[2],
col="purple", lwd=2)
fitGood$coefficients
abline(fitGood$coefficients )
<- seq( 0, 1e5, length.out=213)
lines( x,
fitGood$coefficients[1] + fitGood$coefficients[2]*x, col="blue", lwd=5)
)
x<- seq( 0, 1e5, length.out=213)
lines( x,
fitGood$coefficients[1] + fitGood$coefficients[2]*x,
col="blue", lwd=5)
fitBad<- lm( Y~X)
abline( fitBad$coefficients, col="orange4")
fitBad<- lm( Y~X)
abline( fitBad$coefficients, col="orange4")
Y<- AudiA4$price
X<- AudiA4$mileage
fitBad<- lm( Y ~ X)
abline( fitBad$coefficients, col="orange4")
abline( fitBad$coefficients, col="orange4", lwd=3)
# diagnostic
plot( fitBad$fitted.values, fitBad$residuals)
abline(h=0, col="grey")
plot( fitGood$fitted.values, fitGood$residuals)
names( fitGood)
